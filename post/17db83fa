<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 5.4.0"><meta charset="utf-8"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="HandheldFriendly" content="True"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#f8f8f8"><title>Kubernetes基本介绍与集群部署 - Abnerwei</title><meta name="description" content="Kubernetes集群Kubernetes是一个完备的分布式系统支撑平台，具有完备的集群管理能力，多扩多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和发现机制、內建智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制以及多粒度的资源配额管理能力。同时Kubernetes提供完善的管理工具，涵盖了包括开发、部署测试、运维监控在内的各个环"><meta property="og:type" content="article"><meta property="og:title" content="Kubernetes基本介绍与集群部署"><meta property="og:url" content="https://abnerwei.com/post/17db83fa"><meta property="og:site_name" content="Abnerwei"><meta property="og:description" content="Kubernetes集群Kubernetes是一个完备的分布式系统支撑平台，具有完备的集群管理能力，多扩多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和发现机制、內建智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制以及多粒度的资源配额管理能力。同时Kubernetes提供完善的管理工具，涵盖了包括开发、部署测试、运维监控在内的各个环"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://seo-1255598498.file.myqcloud.com/full/27fcbaf22034200f199a9921cb544e3773282f57.jpg"><meta property="og:image" content="http://images2015.cnblogs.com/blog/1087716/201704/1087716-20170401135152164-1257503094.png"><meta property="og:image" content="http://images2015.cnblogs.com/blog/1087716/201704/1087716-20170414113959283-1890538499.png"><meta property="og:image" content="http://images2015.cnblogs.com/blog/1087716/201704/1087716-20170414114025955-844774077.png"><meta property="og:image" content="http://images2015.cnblogs.com/blog/1087716/201704/1087716-20170414114047517-677453441.png"><meta property="article:published_time" content="2017-12-31T23:30:21.000Z"><meta property="article:modified_time" content="2017-12-31T23:30:21.000Z"><meta property="article:author" content="Abnerwei"><meta property="article:tag" content="Kubernetes"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="http://seo-1255598498.file.myqcloud.com/full/27fcbaf22034200f199a9921cb544e3773282f57.jpg"><link rel="alternate" href="/atom.xml" title="Abnerwei" type="application/atom+xml"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"></head><body><div class="l_body" id="start"><aside class="l_left" layout="post"><header class="header"><div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.2/avatar/round/rainbow64@3x.webp)"></div><img no-lazy class="avatar" src="https://cdn.jsdelivr.net/gh/abnerwei/cdn/logo/avatar.jpeg" onerror="javascript:this.classList.add('error');this.src='https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/image/2659360.svg';"></a><a class="title" href="/"><div class="main">Abnerwei</div><div class="sub normal cap">人活到极致, 一定是素与简</div><div class="sub hover cap" style="opacity:0">abnerwei.com</div></a></div><nav class="menu dis-select"><a class="nav-item active" href="/">博文</a><a class="nav-item" href="/wiki/">文档</a><a class="nav-item" href="/notes/">便笺</a><a class="nav-item" href="/about/">我是谁</a></nav></header><div class="widgets"><div class="widget-wrap" id="toc"><div class="widget-header cap dis-select"><span class="name">本文目录</span></div><div class="widget-body fs14 post"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Service%E6%98%AF%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84%E7%9A%84%E6%A0%B8%E5%BF%83"><span class="toc-text">Service是分布式集群架构的核心</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kubernetes%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5"><span class="toc-text">Kubernetes核心概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Kubernetes%E6%9E%B6%E6%9E%84%E5%92%8C%E7%BB%84%E4%BB%B6"><span class="toc-text">Kubernetes架构和组件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Kubernetes%E7%BB%84%E4%BB%B6"><span class="toc-text">Kubernetes组件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kubernetes-Node%E8%BF%90%E8%A1%8C%E8%8A%82%E7%82%B9%EF%BC%8C%E8%BF%90%E8%A1%8C%E7%AE%A1%E7%90%86%E4%B8%9A%E5%8A%A1%E5%AE%B9%E5%99%A8"><span class="toc-text">Kubernetes Node运行节点，运行管理业务容器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Git-Jenkins-Kubernetes-Docker-Etcd-confd-Nginx-Glusterfs%E6%9E%B6%E6%9E%84%EF%BC%9A"><span class="toc-text">Git+Jenkins+Kubernetes+Docker+Etcd+confd+Nginx+Glusterfs架构：</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%EF%BC%9A"><span class="toc-text">环境：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Master%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE"><span class="toc-text">Master安装与配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MINION%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE-%E6%AF%8F%E5%8F%B0minion%E6%9C%BA%E5%99%A8%E9%83%BD%E6%8C%89%E5%A6%82%E4%B8%8B%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE"><span class="toc-text">MINION安装配置(每台minion机器都按如下安装配置)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E5%AE%8C%E6%88%90%E9%AA%8C%E8%AF%81%E5%AE%89%E8%A3%85"><span class="toc-text">配置完成验证安装</span></a></li></ol></li></ol></li></ol></div></div></div></div><footer class="footer dis-select"><div class="social-wrap"><a class="social" title="RSS" href="/atom.xml" rel="noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/social/25678f144c438.svg"></a><a class="social" title="GitHub" href="https://github.com/abnerwei" target="_blank" rel="external nofollow noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/social/08a41b181ce68.svg"></a><a class="social" title="Comments" href="/about/#comments" rel="noopener noreferrer"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/social/942ebbf1a4b91.svg"></a></div></footer></aside><div class="l_main"><div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/%E6%9C%8D%E5%8A%A1%E5%AE%B9%E5%99%A8/">服务容器</a></div><div id="post-meta">发布于&nbsp;<time datetime="2017-12-31T23:30:21.000Z">2018-01-01</time></div></div><article class="content md post"><h1 class="article-title"><span>Kubernetes基本介绍与集群部署</span></h1><h1 id="Kubernetes集群"><a href="#Kubernetes集群" class="headerlink" title="Kubernetes集群"></a>Kubernetes集群</h1><p>Kubernetes是一个完备的分布式系统支撑平台，具有完备的集群管理能力，多扩多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和发现机制、內建智能负载均衡器、强大的故障发现和自我修复能力、服务滚动升级和在线扩容能力、可扩展的资源自动调度机制以及多粒度的资源配额管理能力。同时Kubernetes提供完善的管理工具，涵盖了包括开发、部署测试、运维监控在内的各个环节。</p><span id="more"></span><h2 id="Service是分布式集群架构的核心"><a href="#Service是分布式集群架构的核心" class="headerlink" title="Service是分布式集群架构的核心"></a>Service是分布式集群架构的核心</h2><p>Service对象拥有以下属性：</p><ul><li>拥有一个唯一指定的名字</li><li>拥有一个虚拟IP（Cluster IP、Service IP、VIP）和端口号</li><li>能够体现某种远程服务能力</li><li>被映射到了提供这种服务能力的一组容器应用上</li></ul><p>容器提供强大的隔离功能，所有有必要把为Service提供服务的这组服务的这组进程放入容器中进行隔离。</p><p>为了建立Service与Pod间的关联管理，Kubernetes给每个Pod贴上一个标签Label，比如运行MySQL的Pod贴上name=mysql标签，给运行PHP的Pod贴上name=php标签，然后给相应的Service定义标签选择器Label Selector，这样就能巧解决Service于Pod的关联问题。</p><p>　　在集群管理方面，Kubernetes将集群中的机器划分为一个Master节点和一群工作节点Node，其中，在Master节点运行着集群管理相关的一组进程kube-apiserver、kube-controller-manager和kube-scheduler，这些进程实现了整个集群的资源管理、Pod调度、弹性伸缩、安全控制、系统监控和纠错等管理能力，并且都是全自动完成的。Node作为集群中的工作节点，运行真正的应用程序，在Node上Kubernetes管理的最小运行单元是Pod。Node上运行着Kubernetes的kubelet、kube-proxy服务进程，这些服务进程负责Pod的创建、启动、监控、重启、销毁以及实现软件模式的负载均衡器。</p><p>　　在Kubernetes集群中，它解决了传统IT系统中服务扩容和升级的两大难题。你只需为需要扩容的Service关联的Pod创建一个Replication Controller简称（RC），则该Service的扩容及后续的升级等问题将迎刃而解。在一个RC定义文件中包括以下3个关键信息。</p><ul><li>目标Pod的定义</li><li>目标Pod需要运行的副本数量（Replicas）</li><li>要监控的目标Pod标签（Label）</li></ul><p>在创建好RC后，Kubernetes会通过RC中定义的的Label筛选出对应Pod实例并实时监控其状态和数量，如果实例数量少于定义的副本数量，则会根据RC中定义的Pod模板来创建一个新的Pod，然后将新Pod调度到合适的Node上启动运行，直到Pod实例的数量达到预定目标。</p><h2 id="Kubernetes核心概念"><a href="#Kubernetes核心概念" class="headerlink" title="Kubernetes核心概念"></a>Kubernetes核心概念</h2><ol><li><p>Master</p><p>k8s集群的管理节点，负责管理集群，提供集群的资源数据访问入口。拥有Etcd存储服务（可选），运行Api Server进程，Controller Manager服务进程及Scheduler服务进程，关联工作节点Node。Kubernetes API server提供HTTP Rest接口的关键服务进程，是Kubernetes里所有资源的增、删、改、查等操作的唯一入口。也是集群控制的入口进程；Kubernetes Controller Manager是Kubernetes所有资源对象的自动化控制中心；Kubernetes Schedule是负责资源调度（Pod调度）的进程</p></li><li><p>Node</p><p>Node是Kubernetes集群架构中运行Pod的服务节点（亦叫agent或minion）。Node是Kubernetes集群操作的单元，用来承载被分配Pod的运行，是Pod运行的宿主机。关联Master管理节点，拥有名称和IP、系统资源信息。运行docker eninge服务，守护进程kunelet及负载均衡器kube-proxy.</p><ul><li>每个Node节点都运行着以下一组关键进程</li><li>kubelet：负责对Pod对于的容器的创建、启停等任务</li><li>kube-proxy：实现Kubernetes Service的通信与负载均衡机制的重要组件</li><li>Docker Engine（Docker）：Docker引擎，负责本机容器的创建和管理工作</li></ul><p>Node节点可以在运行期间动态增加到Kubernetes集群中，默认情况下，kubelet会想master注册自己，这也是Kubernetes推荐的Node管理方式，kubelet进程会定时向Master汇报自身情报，如操作系统、Docker版本、CPU和内存，以及有哪些Pod在运行等等，这样Master可以获知每个Node节点的资源使用情况，冰实现高效均衡的资源调度策略。</p></li><li><p>Pod</p><p>运行于Node节点上，若干相关容器的组合。Pod内包含的容器运行在同一宿主机上，使用相同的网络命名空间、IP地址和端口，能够通过localhost进行通。Pod是Kurbernetes进行创建、调度和管理的最小单位，它提供了比容器更高层次的抽象，使得部署和管理更加灵活。一个Pod可以包含一个容器或者多个相关容器。</p><p>Pod其实有两种类型：普通Pod和静态Pod，后者比较特殊，它并不存在Kubernetes的etcd存储中，而是存放在某个具体的Node上的一个具体文件中，并且只在此Node上启动。普通Pod一旦被创建，就会被放入etcd存储中，随后会被Kubernetes Master调度到摸个具体的Node上进行绑定，随后该Pod被对应的Node上的kubelet进程实例化成一组相关的Docker容器冰启动起来，在。在默认情况下，当Pod里的某个容器停止时，Kubernetes会自动检测到这个问起并且重启这个Pod（重启Pod里的所有容器），如果Pod所在的Node宕机，则会将这个Node上的所有Pod重新调度到其他节点上。</p></li><li><p>Replication Controller</p><p>Replication Controller用来管理Pod的副本，保证集群中存在指定数量的Pod副本。集群中副本的数量大于指定数量，则会停止指定数量之外的多余容器数量，反之，则会启动少于指定数量个数的容器，保证数量不变。Replication Controller是实现弹性伸缩、动态扩容和滚动升级的核心。</p></li><li><p>Service</p><p>Service定义了Pod的逻辑集合和访问该集合的策略，是真实服务的抽象。Service提供了一个统一的服务访问入口以及服务代理和发现机制，关联多个相同Label的Pod，用户不需要了解后台Pod是如何运行。</p><p>外部系统访问Service的问题,首先需要弄明白Kubernetes的三种IP这个问题</p><ul><li>Node IP：Node节点的IP地址</li><li>Pod IP： Pod的IP地址</li><li>Cluster IP：Service的IP地址</li></ul><p>首先,Node IP是Kubernetes集群中节点的物理网卡IP地址，所有属于这个网络的服务器之间都能通过这个网络直接通信。这也表明Kubernetes集群之外的节点访问Kubernetes集群之内的某个节点或者TCP/IP服务的时候，必须通过Node IP进行通信</p><p>其次，Pod IP是每个Pod的IP地址，他是Docker Engine根据docker0网桥的IP地址段进行分配的，通常是一个虚拟的二层网络。</p><p>最后Cluster IP是一个虚拟的IP，但更像是一个伪造的IP网络，原因有以下几点</p><ul><li>Cluster IP仅仅作用于Kubernetes Service这个对象，并由Kubernetes管理和分配P地址</li><li>Cluster IP无法被ping，他没有一个”实体网络对象”来响应</li><li>Cluster IP只能结合Service Port组成一个具体的通信端口，单独的Cluster IP不具备通信的基础，并且他们属于Kubernetes集群这样一个封闭的空间。</li></ul><p>Kubernetes集群之内，Node IP网、Pod IP网于Cluster IP网之间的通信，采用的是Kubernetes自己设计的一种编程方式的特殊路由规则。</p></li><li><p>Label</p><p>Kubernetes中的任意API对象都是通过Label进行标识，Label的实质是一系列的Key/Value键值对，其中key于value由用户自己指定。Label可以附加在各种资源对象上，如Node、Pod、Service、RC等，一个资源对象可以定义任意数量的Label，同一个Label也可以被添加到任意数量的资源对象上去。Label是Replication Controller和Service运行的基础，二者通过Label来进行关联Node上运行的Pod。</p><p>我们可以通过给指定的资源对象捆绑一个或者多个不同的Label来实现多维度的资源分组管理功能，以便于灵活、方便的进行资源分配、调度、配置等管理工作。</p><p>一些常用的Label如下：</p><ul><li>版本标签：”release”:”stable”,”release”:”canary”……</li><li>环境标签：”environment”:”dev”,”environment”:”qa”,”environment”:”production”</li><li>架构标签：”tier”:”frontend”,”tier”:”backend”,”tier”:”middleware”</li><li>分区标签：”partition”:”customerA”,”partition”:”customerB”</li><li>质量管控标签：”track”:”daily”,”track”:”weekly”</li></ul><p>Label相当于我们熟悉的标签，给某个资源对象定义一个Label就相当于给它大了一个标签，随后可以通过Label Selector（标签选择器）查询和筛选拥有某些Label的资源对象，Kubernetes通过这种方式实现了类似SQL的简单又通用的对象查询机制。</p><p>Label Selector在Kubernetes中重要使用场景如下:</p><ul><li>kube-Controller进程通过资源对象RC上定义Label Selector来筛选要监控的Pod副本的数量，从而实现副本数量始终符合预期设定的全自动控制流程</li><li>kube-proxy进程通过Service的Label Selector来选择对应的Pod，自动建立起每个Service岛对应Pod的请求转发路由表，从而实现Service的智能负载均衡</li><li>通过对某些Node定义特定的Label，并且在Pod定义文件中使用Nodeselector这种标签调度策略，kuber-scheduler进程可以实现Pod”定向调度”的特性</li></ul></li></ol><h2 id="Kubernetes架构和组件"><a href="#Kubernetes架构和组件" class="headerlink" title="Kubernetes架构和组件"></a>Kubernetes架构和组件</h2><p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="http://seo-1255598498.file.myqcloud.com/full/27fcbaf22034200f199a9921cb544e3773282f57.jpg" alt="photo1"></p><h3 id="Kubernetes组件"><a href="#Kubernetes组件" class="headerlink" title="Kubernetes组件"></a>Kubernetes组件</h3><p>Kubernetes Master控制组件，调度管理整个系统（集群），包含如下组件:</p><ol><li><p>Kubernetes API Server</p><p>作为Kubernetes系统的入口，其封装了核心对象的增删改查操作，以RESTful API接口方式提供给外部客户和内部组件调用。维护的REST对象持久化到Etcd中存储。</p></li><li><p>Kubernetes Scheduler<br>为新建立的Pod进行节点(node)选择(即分配机器)，负责集群的资源调度。组件抽离，可以方便替换成其他调度器。</p></li><li><p>Kubernetes Controller</p><p>负责执行各种控制器，目前已经提供了很多控制器来保证Kubernetes的正常运行。</p></li><li><p>Replication Controller</p><p>管理维护Replication Controller，关联Replication Controller和Pod，保证Replication Controller定义的副本数量与实际运行Pod数量一致。</p></li><li><p>Node Controller</p><p>管理维护Node，定期检查Node的健康状态，标识出(失效|未失效)的Node节点。</p></li><li><p>Namespace Controller</p><p>管理维护Namespace，定期清理无效的Namespace，包括Namesapce下的API对象，比如Pod、Service等。</p></li><li><p>Service Controller</p><p>管理维护Service，提供负载以及服务代理。</p></li><li><p>EndPoints Controller</p><p>管理维护Endpoints，关联Service和Pod，创建Endpoints为Service的后端，当Pod发生变化时，实时更新Endpoints。</p></li><li><p>Service Account Controller</p><p>管理维护Service Account，为每个Namespace创建默认的Service Account，同时为Service Account创建Service Account Secret。</p></li><li><p>Persistent Volume Controller</p><p>管理维护Persistent Volume和Persistent Volume Claim，为新的Persistent Volume Claim分配Persistent Volume进行绑定，为释放的Persistent Volume执行清理回收。</p></li><li><p>Daemon Set Controller</p><p>管理维护Daemon Set，负责创建Daemon Pod，保证指定的Node上正常的运行Daemon Pod。</p></li><li><p>Deployment Controller</p><p>管理维护Deployment，关联Deployment和Replication Controller，保证运行指定数量的Pod。当Deployment更新时，控制实现Replication Controller和　Pod的更新。</p></li><li><p>Job Controller</p><p>管理维护Job，为Jod创建一次性任务Pod，保证完成Job指定完成的任务数目</p></li><li><p>Pod Autoscaler Controller</p><p>实现Pod的自动伸缩，定时获取监控数据，进行策略匹配，当满足条件时执行Pod的伸缩动作。</p></li></ol><h3 id="Kubernetes-Node运行节点，运行管理业务容器"><a href="#Kubernetes-Node运行节点，运行管理业务容器" class="headerlink" title="Kubernetes Node运行节点，运行管理业务容器"></a>Kubernetes Node运行节点，运行管理业务容器</h3><ol><li><p>Kubelet</p><p>负责管控容器，Kubelet会从Kubernetes API Server接收Pod的创建请求，启动和停止容器，监控容器运行状态并汇报给Kubernetes API Server。</p></li><li><p>Kubernetes Proxy</p><p>负责为Pod创建代理服务，Kubernetes Proxy会从Kubernetes API Server获取所有的Service信息，并根据Service的信息创建代理服务，实现Service到Pod的请求路由和转发，从而实现Kubernetes层级的虚拟转发网络。</p></li><li><p>Docker</p><p>Node上需要运行容器服务</p></li></ol><h1 id="基于kubernetes构建Docker集群环境实战"><a href="#基于kubernetes构建Docker集群环境实战" class="headerlink" title="基于kubernetes构建Docker集群环境实战"></a>基于kubernetes构建Docker集群环境实战</h1><p>kubernetes是google公司基于docker所做的一个分布式集群，有以下主件组成</p><ul><li>etcd: 高可用存储共享配置和服务发现，作为与minion机器上的flannel配套使用，作用是使每台 minion上运行的docker拥有不同的ip段，最终目的是使不同minion上正在运行的docker containner都有一个与别的任意一个containner（别的minion上运行的docker containner）不一样的IP地址。</li><li>flannel: 网络结构支持</li><li>kube-apiserver: 不论通过kubectl还是使用remote api 直接控制，都要经过apiserver</li><li>kube-controller-manager: 对replication controller, endpoints controller, namespace controller, and serviceaccounts controller的循环控制，与kube-apiserver交互，保证这些controller工作</li><li>kube-scheduler: Kubernetes scheduler的作用就是根据特定的调度算法将pod调度到指定的工作节点（minion）上，这一过程也叫绑定（bind)</li><li>kubelet: Kubelet运行在Kubernetes Minion Node上. 它是container agent的逻辑继任者</li><li>kube-proxy: kube-proxy是kubernetes 里运行在minion节点上的一个组件, 它起的作用是一个服务代理的角色</li></ul><h3 id="Git-Jenkins-Kubernetes-Docker-Etcd-confd-Nginx-Glusterfs架构："><a href="#Git-Jenkins-Kubernetes-Docker-Etcd-confd-Nginx-Glusterfs架构：" class="headerlink" title="Git+Jenkins+Kubernetes+Docker+Etcd+confd+Nginx+Glusterfs架构："></a>Git+Jenkins+Kubernetes+Docker+Etcd+confd+Nginx+Glusterfs架构：</h3><p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="http://images2015.cnblogs.com/blog/1087716/201704/1087716-20170401135152164-1257503094.png" alt="git"></p><h4 id="环境："><a href="#环境：" class="headerlink" title="环境："></a>环境：</h4><p>centos7系统机器三台：</p><pre><code>10.0.0.81: 用来安装kubernetes master
10.0.0.82: 用作kubernetes minion （minion1）
10.0.0.83: 用作kubbernetes minion (minion2)
</code></pre><h4 id="Master安装与配置"><a href="#Master安装与配置" class="headerlink" title="Master安装与配置"></a>Master安装与配置</h4><ol><li><p>安装并配置Kubernetes master(yum 方式)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> yum -y install etcd kubernetes</span></span><br></pre></td></tr></table></figure><p>配置etcd。确保一下配置项正确:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">vim /etc/etcd/etcd.conf</span></span><br><span class="line">  </span><br><span class="line">ETCD_NAME=default</span><br><span class="line">ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;</span><br><span class="line">ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379&quot;</span><br><span class="line">ETCD_ADVERTISE_CLIENT_URLS=&quot;http://localhost:2379&quot;</span><br></pre></td></tr></table></figure><p>配置kubernetes</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/kubernetes/apiserver</span><br><span class="line">  </span><br><span class="line">KUBE_API_ADDRESS=&quot;--address=0.0.0.0&quot;KUBE_API_PORT=&quot;--port=8080&quot;</span><br><span class="line">KUBELET_PORT=&quot;--kubelet_port=10250&quot;</span><br><span class="line">KUBE_ETCD_SERVERS=&quot;--etcd_servers=http://127.0.0.1:2379&quot;</span><br><span class="line">KUBE_SERVICE_ADDRESSES=&quot;--service-cluster-ip-range=10.254.0.0/16&quot;</span><br><span class="line">KUBE_ADMISSION_CONTROL=&quot;--admission_control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ResourceQuota&quot;</span><br><span class="line">KUBE_API_ARGS=&quot;&quot;</span><br></pre></td></tr></table></figure></li><li><p>启动etcd, kube-apiserver, kube-controller-manager and kube-scheduler服务</p></li><li><p>设置etcd网络</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">etcdctl -C 10.0.0.81:2379 <span class="built_in">set</span> /atomic.io/network/config <span class="string">&#x27;&#123;&quot;Network&quot;:&quot;10.1.0.0/16&quot;&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure></li><li><p>至此master配置完成，运行kubectl get nodes可以查看有多少minion在运行，以及其状态。这里我们的minion还都没有开始安装配置，所以运行之后结果为空</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl get nodes NAME LABELS STATUS</span></span><br></pre></td></tr></table></figure><h4 id="MINION安装配置-每台minion机器都按如下安装配置"><a href="#MINION安装配置-每台minion机器都按如下安装配置" class="headerlink" title="MINION安装配置(每台minion机器都按如下安装配置)"></a>MINION安装配置(每台minion机器都按如下安装配置)</h4></li><li><p>环境安装与配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> yum -y install flannel kubernetes</span></span><br></pre></td></tr></table></figure><p>配置Kubernetes连接的服务端IP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">vim /etc/kubernetes/config</span></span><br><span class="line">KUBE_MASTER=&quot;--master=http://10.0.0.81:8080&quot;</span><br><span class="line">KUBE_ETCD_SERVERS=&quot;--etcd_servers=http://10.0.0.81:2379&quot;</span><br></pre></td></tr></table></figure><p>配置kubernetes ,（请使用每台minion自己的IP地址比如10.0.0.81：代替下面的$LOCALIP）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">vim /etc/kubernetes/kubelet&lt;br&gt;KUBELET_ADDRESS=<span class="string">&quot;--address=0.0.0.0&quot;</span></span></span><br><span class="line">KUBELET_PORT=&quot;--port=10250&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> change the hostname to this host’s IP address KUBELET_HOSTNAME=<span class="string">&quot;--hostname_override=<span class="variable">$LOCALIP</span>&quot;</span></span></span><br><span class="line">KUBELET_API_SERVER=&quot;--api_servers=http://10.0.0.81:8080&quot;</span><br><span class="line">KUBELET_ARGS=&quot;&quot;</span><br></pre></td></tr></table></figure></li><li><p>准备启动服务（如果本来机器上已经运行过docker的请看过来，没有运行过的请忽略此步骤）<br>运行ifconfig，查看机器的网络配置情况（有docker0）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ifconfig docker0</span></span><br><span class="line"> Link encap:Ethernet HWaddr 02:42:B2:75:2E:67 inet addr:172.17.0.1 Bcast:0.0.0.0 Mask:255.255.0.0 UP</span><br><span class="line"> BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0</span><br><span class="line"> errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0</span><br><span class="line"> RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) </span><br></pre></td></tr></table></figure><p>warning:在运行过docker的机器上可以看到有docker0，这里在启动服务之前需要删掉docker0配置，在命令行运行:sudo ip link delete docker0</p></li><li><p>配置flannel网络</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">vim /etc/sysconfig/flanneld</span></span><br><span class="line">FLANNEL_ETCD_ENDPOINTS=&quot;http://10.0.0.81:2379&quot;</span><br><span class="line">FLANNEL_ETCD_PREFIX=&quot;/atomic.io/network&quot;　</span><br></pre></td></tr></table></figure><blockquote><p>PS：其中atomic.io与上面etcd中的Network对应</p></blockquote></li></ol><h4 id="配置完成验证安装"><a href="#配置完成验证安装" class="headerlink" title="配置完成验证安装"></a>配置完成验证安装</h4><p>确定两台minion(10.0.0.82和10.0.0.83)和一台master（10.0.0.81）都已经成功的安装配置并且服务都已经启动了。<br>切换到master机器上，运行命令kubectl get nodes</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl get nodes</span></span><br><span class="line">NAME STATUS AGE</span><br><span class="line">10.0.0.82 Ready 1m</span><br><span class="line">10.0.0.83 Ready 1m</span><br></pre></td></tr></table></figure><h1 id="Kubernetes-Pod"><a href="#Kubernetes-Pod" class="headerlink" title="Kubernetes Pod"></a>Kubernetes Pod</h1><ol><li><p>yaml格式的Pod配置文件内容及注解</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span>       <span class="comment">#必选，版本号，例如v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span>       <span class="comment">#必选，Pod</span></span><br><span class="line"><span class="attr">metadata:</span>       <span class="comment">#必选，元数据</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">string</span>       <span class="comment">#必选，Pod名称</span></span><br><span class="line"><span class="attr">namespace:</span> <span class="string">string</span>    <span class="comment">#必选，Pod所属的命名空间</span></span><br><span class="line"><span class="attr">labels:</span>      <span class="comment">#自定义标签</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>     <span class="comment">#自定义标签名字</span></span><br><span class="line"><span class="attr">annotations:</span>       <span class="comment">#自定义注释列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span></span><br><span class="line"><span class="attr">spec:</span>         <span class="comment">#必选，Pod中容器的详细定义</span></span><br><span class="line"><span class="attr">containers:</span>      <span class="comment">#必选，Pod中容器列表</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>     <span class="comment">#必选，容器名称</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">string</span>    <span class="comment">#必选，容器的镜像名称</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> [<span class="string">Always</span> <span class="string">|</span> <span class="string">Never</span> <span class="string">|</span> <span class="string">IfNotPresent</span>] <span class="comment">#获取镜像的策略 Alawys表示下载镜像 IfnotPresent表示优先使用本地镜像，否则下载镜像，Nerver表示仅使用本地镜像</span></span><br><span class="line">    <span class="attr">command:</span> [<span class="string">string</span>]    <span class="comment">#容器的启动命令列表，如不指定，使用打包时使用的启动命令</span></span><br><span class="line">    <span class="attr">args:</span> [<span class="string">string</span>]     <span class="comment">#容器的启动命令参数列表</span></span><br><span class="line">    <span class="attr">workingDir:</span> <span class="string">string</span>     <span class="comment">#容器的工作目录</span></span><br><span class="line">    <span class="attr">volumeMounts:</span>    <span class="comment">#挂载到容器内部的存储卷配置</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>     <span class="comment">#引用pod定义的共享存储卷的名称，需用volumes[]部分定义的的卷名</span></span><br><span class="line">    <span class="attr">mountPath:</span> <span class="string">string</span>    <span class="comment">#存储卷在容器内mount的绝对路径，应少于512字符</span></span><br><span class="line">    <span class="attr">readOnly:</span> <span class="string">boolean</span>    <span class="comment">#是否为只读模式</span></span><br><span class="line">    <span class="attr">ports:</span>       <span class="comment">#需要暴露的端口库号列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>     <span class="comment">#端口号名称</span></span><br><span class="line">    <span class="attr">containerPort:</span> <span class="string">int</span>   <span class="comment">#容器需要监听的端口号</span></span><br><span class="line">    <span class="attr">hostPort:</span> <span class="string">int</span>    <span class="comment">#容器所在主机需要监听的端口号，默认与Container相同</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">string</span>     <span class="comment">#端口协议，支持TCP和UDP，默认TCP</span></span><br><span class="line">    <span class="attr">env:</span>       <span class="comment">#容器运行前需设置的环境变量列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>     <span class="comment">#环境变量名称</span></span><br><span class="line">    <span class="attr">value:</span> <span class="string">string</span>    <span class="comment">#环境变量的值</span></span><br><span class="line">    <span class="attr">resources:</span>       <span class="comment">#资源限制和请求的设置</span></span><br><span class="line">    <span class="attr">limits:</span>      <span class="comment">#资源限制的设置</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">string</span>    <span class="comment">#Cpu的限制，单位为core数，将用于docker run --cpu-shares参数</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">string</span>     <span class="comment">#内存限制，单位可以为Mib/Gib，将用于docker run --memory参数</span></span><br><span class="line">    <span class="attr">requests:</span>      <span class="comment">#资源请求的设置</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="string">string</span>    <span class="comment">#Cpu请求，容器启动的初始可用数量</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">string</span>     <span class="comment">#内存清楚，容器启动的初始可用数量</span></span><br><span class="line">    <span class="attr">livenessProbe:</span>     <span class="comment">#对Pod内个容器健康检查的设置，当探测无响应几次后将自动重启该容器，检查方法有exec、httpGet和tcpSocket，对一个容器只需设置其中一种方法即可</span></span><br><span class="line">    <span class="attr">exec:</span>      <span class="comment">#对Pod容器内检查方式设置为exec方式</span></span><br><span class="line">        <span class="attr">command:</span> [<span class="string">string</span>]  <span class="comment">#exec方式需要制定的命令或脚本</span></span><br><span class="line">    <span class="attr">httpGet:</span>       <span class="comment">#对Pod内个容器健康检查方法设置为HttpGet，需要制定Path、port</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">port:</span> <span class="string">number</span></span><br><span class="line">        <span class="attr">host:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">scheme:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">HttpHeaders:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">value:</span> <span class="string">string</span></span><br><span class="line">    <span class="attr">tcpSocket:</span>     <span class="comment">#对Pod内个容器健康检查方式设置为tcpSocket方式</span></span><br><span class="line">        <span class="attr">port:</span> <span class="string">number</span></span><br><span class="line">    <span class="attr">initialDelaySeconds:</span> <span class="number">0</span>  <span class="comment">#容器启动完成后首次探测的时间，单位为秒</span></span><br><span class="line">    <span class="attr">timeoutSeconds:</span> <span class="number">0</span>   <span class="comment">#对容器健康检查探测等待响应的超时时间，单位秒，默认1秒</span></span><br><span class="line">    <span class="attr">periodSeconds:</span> <span class="number">0</span>    <span class="comment">#对容器监控检查的定期探测时间设置，单位秒，默认10秒一次</span></span><br><span class="line">    <span class="attr">successThreshold:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">failureThreshold:</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">securityContext:</span></span><br><span class="line">        <span class="string">privileged:false</span></span><br><span class="line">    <span class="attr">restartPolicy:</span> [<span class="string">Always</span> <span class="string">|</span> <span class="string">Never</span> <span class="string">|</span> <span class="string">OnFailure</span>]<span class="comment">#Pod的重启策略，Always表示一旦不管以何种方式终止运行，kubelet都将重启，OnFailure表示只有Pod以非0退出码退出才重启，Nerver表示不再重启该Pod</span></span><br><span class="line">    <span class="attr">nodeSelector:</span> <span class="string">obeject</span>  <span class="comment">#设置NodeSelector表示将该Pod调度到包含这个label的node上，以key：value的格式指定</span></span><br><span class="line">    <span class="attr">imagePullSecrets:</span>    <span class="comment">#Pull镜像时使用的secret名称，以key：secretkey格式指定</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span></span><br><span class="line">    <span class="string">hostNetwork:false</span>      <span class="comment">#是否使用主机网络模式，默认为false，如果设置为true，表示使用宿主机网络</span></span><br><span class="line">    <span class="attr">volumes:</span>       <span class="comment">#在该pod上定义共享存储卷列表</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">string</span>     <span class="comment">#共享存储卷名称 （volumes类型有很多种）</span></span><br><span class="line">    <span class="attr">emptyDir:</span> &#123;&#125;     <span class="comment">#类型为emtyDir的存储卷，与Pod同生命周期的一个临时目录。为空值</span></span><br><span class="line">    <span class="attr">hostPath:</span> <span class="string">string</span>     <span class="comment">#类型为hostPath的存储卷，表示挂载Pod所在宿主机的目录</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">string</span>     <span class="comment">#Pod所在宿主机的目录，将被用于同期中mount的目录</span></span><br><span class="line">    <span class="attr">secret:</span>      <span class="comment">#类型为secret的存储卷，挂载集群与定义的secre对象到容器内部</span></span><br><span class="line">        <span class="attr">scretname:</span> <span class="string">string</span>  </span><br><span class="line">        <span class="attr">items:</span>     </span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">string</span></span><br><span class="line">    <span class="attr">configMap:</span>     <span class="comment">#类型为configMap的存储卷，挂载预定义的configMap对象到容器内部</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">items:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">string</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">string</span>   </span><br></pre></td></tr></table></figure></li><li><p>Pod基本用法</p><p>在使用docker时，我们可以使用docker run命令创建并启动一个容器，而在Kubernetes系统中对长时间运行的容器要求是：其主程序需要一直在前台运行。如果我们创建的docker镜像的启动命令是后台执行程序，例如Linux脚本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">    　　nohup ./startup.sh &amp;</span><br></pre></td></tr></table></figure><p>则kubelet创建包含这个容器的pod后运行完该命令，即认为Pod执行结束，之后根据RC中定义的pod的replicas副本数量生产一个新的pod，而一旦创建出新的pod，将在执行完命令后陷入无限循环的过程中，这就是Kubernetes需要我们创建的docker镜像以一个前台命令作为启动命令的原因。</p><p>对于无法改造为前台执行的应用，也可以使用开源工具supervisor辅助进行前台运行的功能。</p><p>例如：两个容器应用的前端frontend和redis为紧耦合的关系，应该组合成一个整体对外提供服务，则应该将这两个打包为一个pod.<br>配置文件frontend-localredis-pod.yaml如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">apiVersion:v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">redis-php</span></span><br><span class="line"><span class="attr">label:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">redis-php</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">frontend</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">kubeguide/guestbook-php-frontend:localredis</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containersPort:</span> <span class="number">80</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis-php</span></span><br><span class="line">    <span class="string">image:kubeguide/redis-master</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containersPort:</span> <span class="number">6379</span></span><br></pre></td></tr></table></figure><p>属于一个Pod的多个容器应用之间相互访问只需要通过localhost就可以通信，这一组容器被绑定在一个环境中。<br>　　使用kubectl create创建该Pod后，get Pod信息可以看到如下图：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">kubectl get gods</span></span><br><span class="line">NAME READY STATUS RESTATS AGE</span><br><span class="line">redis-php 2/2Running 0 10m</span><br></pre></td></tr></table></figure><p>可以看到READY信息为2/2，表示Pod中的两个容器都成功运行了.</p><p>查看pod的详细信息，可以看到两个容器的定义和创建过程。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@kubernetes-master ~]# kubectl describe redis-php</span><br><span class="line">the server doesn&#x27;t have a resourcetype &quot;redis-php&quot;</span><br><span class="line">[root@kubernetes-master ~]# kubectl describe pod redis-php</span><br><span class="line">Name: redis-php</span><br><span class="line">Namespace: default</span><br><span class="line">Node: kubernetes-minion/10.0.0.23</span><br><span class="line">Start Time: Wed, 12 Apr 2017 09:14:58 +0800</span><br><span class="line">Labels: name=redis-php</span><br><span class="line">Status: Running</span><br><span class="line">IP: 10.1.24.2</span><br><span class="line">Controllers: &lt;none&gt;</span><br><span class="line">Containers:</span><br><span class="line">nginx:</span><br><span class="line">Container ID: docker://d05b743c200dff7cf3b60b7373a45666be2ebb48b7b8b31ce0ece9be4546ce77</span><br><span class="line">Image: nginx</span><br><span class="line">Image ID: docker-pullable://docker.io/nginx@sha256:e6693c20186f837fc393390135d8a598a96a833917917789d63766cab6c59582</span><br><span class="line">Port: 80/TCP</span><br><span class="line">State: Running</span><br><span class="line">Started: Wed, 12 Apr 2017 09:19:31 +0800</span><br></pre></td></tr></table></figure></li><li><p>静态Pod</p><p>静态pod是由kubelet进行管理的仅存在于特定Node的Pod上，他们不能通过API Server进行管理，无法与ReplicationController、Deployment或者DaemonSet进行关联，并且kubelet无法对他们进行健康检查。静态Pod总是由kubelet进行创建，并且总是在kubelet所在的Node上运行。</p><p>创建静态Pod有两种方式：配置文件或者HTTP方式</p><p>1）配置文件方式</p><p>　　首先，需要设置kubelet的启动参数”–config”,指定kubelet需要监控的配置文件所在的目录，kubelet会定期扫描该目录，冰根据目录中的 .yaml或 .json文件进行创建操作</p><p>假设配置目录为/etc/kubelet.d/配置启动参数:–config=/etc/kubelet.d/,然后重启kubelet服务后，再宿主机受用docker ps或者在Kubernetes Master上都可以看到指定的容器在列表中</p><p>由于静态pod无法通过API Server直接管理，所以在master节点尝试删除该pod，会将其变为pending状态，也不会被删除</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">kubetctl delete pod static-web-node1</span></span><br><span class="line">pod &quot;static-web-node1&quot;deleted</span><br><span class="line"><span class="meta">#</span><span class="bash">kubectl get pods</span></span><br><span class="line">NAME READY STATUS RESTARTS AGE</span><br><span class="line">static-web-node1 0/1Pending 0 1s</span><br></pre></td></tr></table></figure><p>要删除该pod的操作只能在其所在的Node上操作，将其定义的.yaml文件从/etc/kubelet.d/目录下删除</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">rm -f /etc/kubelet.d/static-web.yaml</span></span><br><span class="line"><span class="meta">#</span><span class="bash">docker ps</span></span><br></pre></td></tr></table></figure></li><li><p>Pod容器共享Volume</p><p>Volume类型包括：emtyDir、hostPath、gcePersistentDisk、awsElasticBlockStore、gitRepo、secret、nfs、scsi、glusterfs、persistentVolumeClaim、rbd、flexVolume、cinder、cephfs、flocker、downwardAPI、fc、azureFile、configMap、vsphereVolume等等，可以定义多个Volume，每个Volume的name保持唯一。在同一个pod中的多个容器能够共享pod级别的存储卷Volume。Volume可以定义为各种类型，多个容器各自进行挂载操作，讲一个Volume挂载为容器内需要的目录。<br>如下图：<br><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="http://images2015.cnblogs.com/blog/1087716/201704/1087716-20170414113959283-1890538499.png" alt="pod"></p><p>如上图中的Pod中包含两个容器：tomcat和busybox，在pod级别设置Volume “app-logs”，用于tomcat想其中写日志文件，busybox读日志文件。</p><p>配置文件如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">apiVersion:v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">name: redis-php</span><br><span class="line">label:</span><br><span class="line">    name: volume-pod</span><br><span class="line">spec:</span><br><span class="line">containers:</span><br><span class="line">- name: tomcat</span><br><span class="line">    image: tomcat</span><br><span class="line">    ports:</span><br><span class="line">    - containersPort: 8080</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: app-logs</span><br><span class="line">    mountPath:/usr/local/tomcat/logs</span><br><span class="line">- name: busybox</span><br><span class="line">    image:busybox</span><br><span class="line">    command: [&quot;sh&quot;,&quot;-C&quot;,&quot;tail -f /logs/catalina*.log&quot;]</span><br><span class="line">volumes:</span><br><span class="line">- name: app-logs</span><br><span class="line">    emptyDir:&#123;&#125;</span><br></pre></td></tr></table></figure><p>busybox容器可以通过kubectl logs查看输出内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">kubectl logs volume-pod -c busybox</span>　</span><br></pre></td></tr></table></figure><p>tomcat容器生成的日志文件可以登录容器查看</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">kubectl <span class="built_in">exec</span> -ti volume-pod -c tomcat -- ls /usr/<span class="built_in">local</span>/tomcat/logs</span></span><br></pre></td></tr></table></figure></li><li><p>Pod的配置管理</p><p>应用部署的一个最佳实践是将应用所需的配置信息于程序进行分离，这样可以使得应用程序被更好的复用，通过不用配置文件也能实现更灵活的功能。将应用打包为容器镜像后，可以通过环境变量或外挂文件的方式在创建容器时进行配置注入。ConfigMap是Kubernetes v1.2版本开始提供的一种统一集群配置管理方案。</p><p>5.1 ConfigMap：容器应用的配置管理</p><p>容器使用ConfigMap的典型用法如下：</p><ol><li>生产为容器的环境变量。</li><li>设置容器启动命令的启动参数（需设置为环境变量）。</li><li>以Volume的形式挂载为容器内部的文件或目录。</li></ol><p>ConfigMap以一个或多个key:value的形式保存在Kubernetes系统中共应用使用，既可以用于表示一个变量的值，也可以表示一个完整的配置文件内容。<br>通过yuaml配置文件或者直接使用kubelet create configmap 命令的方式来创建ConfigMap</p><p>5.2 ConfigMap的创建</p><p>举个小例子cm-appvars.yaml来描述将几个应用所需的变量定义为ConfigMap的用法：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> vim cm-appvars.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">name: cm-appvars</span><br><span class="line">data:</span><br><span class="line">apploglevel: info</span><br><span class="line">appdatadir:/var/data</span><br></pre></td></tr></table></figure><p>执行kubectl create命令创建该ConfigMap</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">kubectl create -f cm-appvars.yaml</span></span><br><span class="line">configmap &quot;cm-appvars.yaml&quot;created</span><br></pre></td></tr></table></figure><p>查看建立好的ConfigMap：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">kubectl get configmap</span></span><br><span class="line">NAME DATA AGE</span><br><span class="line">cm-appvars 2 3s</span><br><span class="line">[root@kubernetes-master ~]# kubectl describe configmap cm-appvars</span><br><span class="line">Name: cm-appvars</span><br><span class="line">Namespace: default</span><br><span class="line">Labels: &lt;none&gt;</span><br><span class="line">Annotations: &lt;none&gt;</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">appdatadir: 9 bytes</span><br><span class="line">apploglevel: 4 bytes</span><br><span class="line">[root@kubernetes-master ~]# kubectl get configmap cm-appvars -o yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">data:</span><br><span class="line">appdatadir: /var/data</span><br><span class="line">apploglevel: info</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">creationTimestamp: 2017-04-14T06:03:36Z</span><br><span class="line">name: cm-appvars</span><br><span class="line">namespace: default</span><br><span class="line">resourceVersion:&quot;571221&quot;</span><br><span class="line">selfLink: /api/v1/namespaces/default/configmaps/cm-appvars</span><br><span class="line">uid: 190323cb-20d8-11e7-94ec-000c29ac8d83　</span><br></pre></td></tr></table></figure><p>另：创建一个cm-appconfigfile.yaml描述将两个配置文件server.xml和logging.properties定义为configmap的用法，设置key为配置文件的别名，value则是配置文件的文本内容：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">cm-appvars</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line"><span class="attr">key-serverxml:</span></span><br><span class="line">    <span class="string">&lt;?xml</span> <span class="string">Version=&#x27;1.0&#x27;encoding=&#x27;utf-8&#x27;?&gt;</span></span><br><span class="line">    <span class="string">&lt;Server</span> <span class="string">port=&quot;8005&quot;shutdown=&quot;SHUTDOWN&quot;&gt;</span></span><br><span class="line">    <span class="string">.....</span></span><br><span class="line">    <span class="string">&lt;/service&gt;</span></span><br><span class="line">    <span class="string">&lt;/Server&gt;</span></span><br><span class="line"><span class="attr">key-loggingproperties:</span></span><br><span class="line">    <span class="string">&quot;handlers=lcatalina.org.apache.juli.FileHandler,</span></span><br><span class="line"><span class="string">    ....&quot;</span></span><br></pre></td></tr></table></figure><p>在pod “cm-test-app”定义中，将configmap “cm-appconfigfile”中的内容以文件形式mount到容器内部configfiles目录中。<br>Pod配置文件cm-test-app.yaml内容如下：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#vim cm-test-app.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">cm-test-app</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cm-test-app</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">tomcat-app:v1</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">serverxml</span>                          <span class="comment">#引用volume名</span></span><br><span class="line">    <span class="string">mountPath:/configfiles</span>                       <span class="comment">#挂载到容器内部目录</span></span><br><span class="line">        <span class="attr">configMap:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">cm-test-appconfigfile</span>                  <span class="comment">#使用configmap定义的的cm-appconfigfile</span></span><br><span class="line">        <span class="attr">items:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">key-serverxml</span>                     <span class="comment">#将key=key-serverxml</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">server.xml</span>                           <span class="comment">#value将server.xml文件名进行挂载</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">key-loggingproperties</span>                 <span class="comment">#将key=key-loggingproperties    </span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">logging.properties</span>                   <span class="comment">#value将logging.properties文件名进行挂载　</span></span><br></pre></td></tr></table></figure><p>创建Pod：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">kubectl create -f cm-test-app.yaml</span></span><br><span class="line">Pod &quot;cm-test-app&quot;created　　</span><br></pre></td></tr></table></figure><p>登录容器查看configfiles目录下的server.xml和logging.properties文件，他们的内容就是configmap “cm-appconfigfile”中定义的两个key的内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">kubectl <span class="built_in">exec</span> -ti cm-test-app -- bash</span></span><br><span class="line">root@cm-rest-app:/# cat /configfiles/server.xml</span><br><span class="line">root@cm-rest-app:/# cat /configfiles/logging.properties</span><br></pre></td></tr></table></figure><p>5.3 使用ConfigMap的条件限制</p><p>使用configmap的限制条件如下：</p><ul><li>configmap必须在pod之间创建</li><li>configmap也可以定义为属于某个Namespace，只有处于相同namespaces中的pod可以引用</li><li>configmap中配额管理还未能实现</li><li>kubelet只支持被api server管理的pod使用configmap，静态pod无法引用</li><li>在pod对configmap进行挂载操作时，容器内部职能挂载为目录，无法挂载文件。</li></ul></li><li><p>Pod生命周期和重启策略</p><p>Pod在整个生命周期过程中被定义为各种状态，熟悉Pod的各种状态有助于理解如何设置Pod的调度策略、重启策略<br>Pod的状态包含以下几种，如图：</p><p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="http://images2015.cnblogs.com/blog/1087716/201704/1087716-20170414114025955-844774077.png" alt="podlife"></p><p>Pod的重启策略（RestartPolicy）应用于Pod内所有的容器，并且仅在Pod所处的Node上由kubelet进行判断和重启操作。当某哥容器异常退出或者健康检查石柏师，kubelet将根据RestartPolicy的设置进行相应的操作</p><p>Pod的重启策略包括Always、OnFailure及Nerver，默认值为Always。</p><p>kubelet重启失效容器的时间间隔以sync-frequency乘以2n来计算，例如1、2、4、8倍等，最长延时5分钟，并且成功重启后的10分钟后重置该事件。</p><p>Pod的重启策略和控制方式息息相关，当前可用于管理Pod的控制器宝库ReplicationController、Job、DaemonSet及直接通过kubelet管理（静态Pod），每种控制器对Pod的重启策略要求如下：</p><ul><li>RC和DaemonSet：必须设置为Always，需要保证该容器持续运行</li><li>Job：OnFailure或Nerver，确保容器执行完成后不再重启</li><li>kubelet：在Pod失效时重启他，不论RestartPolicy设置什么值，并且也不会对Pod进行健康检查</li></ul></li><li><p>Pod健康检查</p><p>对Pod的健康检查可以通过两类探针来检查：LivenessProbe和ReadinessProbe</p><ul><li>LivenessProbe探针：用于判断容器是否存活（running状态），如果LivenessProbe探针探测到容器不健康，则kubelet杀掉该容器，并根据容器的重启策略做响应处理</li><li>ReadinessProbe探针：用于判断容器是否启动完成（ready状态），可以接受请求。如果ReadinessProbe探针探测失败，则Pod的状态被修改。Endpoint Controller将从service的Endpoint中删除包含该容器所在的Pod的Endpoint。</li></ul><p>kubelet定制执行LivenessProbe探针来诊断容器的健康状况。LivenessProbe有三种事项方式。</p><p>（1）ExecAction：在容器内部执行一个命令，如果该命令的返回值为0，则表示容器健康</p><p>例：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">apiVersion:v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">name: liveness-exec</span><br><span class="line">label:</span><br><span class="line">    name: liveness</span><br><span class="line">spec:</span><br><span class="line">containers:</span><br><span class="line">- name: tomcat</span><br><span class="line">    image: grc.io/google_containers/tomcat</span><br><span class="line">    args:</span><br><span class="line">    -/bin/sh</span><br><span class="line">    - -c</span><br><span class="line">    -echo ok &gt;/tmp.health;sleep10; rm -fr /tmp/health;sleep600</span><br><span class="line">    livenessProbe:</span><br><span class="line">    exec:</span><br><span class="line">        command:</span><br><span class="line">        -cat</span><br><span class="line">        -/tmp/health</span><br><span class="line">    initianDelaySeconds:15</span><br><span class="line">    timeoutSeconds:1　</span><br></pre></td></tr></table></figure><p>（2）TCPSocketAction：通过容器ip地址和端口号执行TCP检查，如果能够建立tcp连接表明容器健康</p><p>例：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">pod-with-healthcheck</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">    <span class="attr">tcpSocket:</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="string">initianDelaySeconds:30</span></span><br><span class="line">    <span class="string">timeoutSeconds:1</span></span><br></pre></td></tr></table></figure><p>（3）HTTPGetAction：通过容器Ip地址、端口号及路径调用http get方法，如果响应的状态吗大于200且小于400，则认为容器健康</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">apiVersion:v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">pod-with-healthcheck</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">livenessProbe:</span></span><br><span class="line">    <span class="attr">httpGet:</span></span><br><span class="line">        <span class="string">path:/_status/healthz</span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="string">initianDelaySeconds:30</span></span><br><span class="line">    <span class="string">timeoutSeconds:1</span></span><br></pre></td></tr></table></figure><p>对于每种探针方式，都需要设置initialDelaySeconds和timeoutSeconds两个参数，它们含义如下：</p><ul><li>initialDelaySeconds：启动容器后首次监控检查的等待时间，单位秒</li><li>timeouSeconds：健康检查发送请求后等待响应的超时时间，单位秒。当发生超时就被认为容器无法提供服务无，该容器将被重启</li></ul></li><li><p>Pod调度</p><p>在Kubernetes系统中，Pod在大部分场景下都只是容器的载体而已，通常需要通过RC、Deployment、DaemonSet、Job等对象来完成Pod的调度和自动控制功能。</p><p>8.1 RC、Deployment：全自动调度</p><p>RC的主要功能之一就是自动部署容器应用的多份副本，以及持续监控副本的数量，在集群内始终维护用户指定的副本数量。</p><p>在调度策略上，除了使用系统内置的调度算法选择合适的Node进行调度，也可以在Pod的定义中使用NodeSelector或NodeAffinity来指定满足条件的Node进行调度。<br>　　1）NodeSelector:定向调度</p><p>Kubernetes Master上的scheduler服务（kube-Scheduler进程）负责实现Pod的调度，整个过程通过一系列复杂的算法，最终为每个Pod计算出一个最佳的目标节点，通常我们无法知道Pod最终会被调度到哪个节点上。实际情况中，我们需要将Pod调度到我们指定的节点上，可以通过Node的标签和pod的nodeSelector属性相匹配来达到目的。<br>　　（1）首先通过kubectl label命令给目标Node打上标签</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;   </span><br></pre></td></tr></table></figure><p>（2）然后在Pod定义中加上nodeSelector的设置</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">apiVersion:v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line"><span class="attr">label:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">selector:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line">    <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">        <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line">        <span class="attr">images:</span> <span class="string">kubeguide/redis-master</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">6379</span></span><br><span class="line">        <span class="attr">nodeSelector:</span></span><br><span class="line">        <span class="attr">zone:</span> <span class="string">north</span>　</span><br></pre></td></tr></table></figure><p>运行kubectl create -f命令创建Pod，scheduler就会将该Pod调度到拥有zone=north标签的Node上。 如果多个Node拥有该标签，则会根据调度算法在该组Node上选一个可用的进行Pod调度。</p><p>需要注意的是：如果集群中没有拥有该标签的Node，则这个Pod也无法被成功调度。</p><p>2）NodeAffinity：亲和性调度</p><p>该调度策略是将来替换NodeSelector的新一代调度策略。由于NodeSelector通过Node的Label进行精确匹配，所有NodeAffinity增加了In、NotIn、Exists、DoesNotexist、Gt、Lt等操作符来选择Node。调度侧露更加灵活。</p><p>8.2 DaemonSet：特定场景调度</p><p>DaemonSet用于管理集群中每个Node上仅运行一份Pod的副本实例，如图</p><p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="http://images2015.cnblogs.com/blog/1087716/201704/1087716-20170414114047517-677453441.png" alt="Daemon"></p><p>这种用法适合一些有下列需求的应用：</p><ul><li>在每个Node上运行个以GlusterFS存储或者ceph存储的daemon进程</li><li>在每个Node上运行一个日志采集程序，例如fluentd或者logstach</li><li>在每个Node上运行一个健康程序，采集Node的性能数据。</li></ul><p>DaemonSet的Pod调度策略类似于RC，除了使用系统内置的算法在每台Node上进行调度，也可以在Pod的定义中使用NodeSelector或NodeAffinity来指定满足条件的Node范围来进行调度。</p><p>8.3 批处理调度</p></li><li><p>Pod的扩容和缩荣</p><p>在实际生产环境中，我们经常遇到某个服务需要扩容的场景，也有可能因为资源精确需要缩减资源而需要减少服务实例数量，此时我们可以Kubernetes中RC提供scale机制来完成这些工作。</p><p>以redis-slave RC为例，已定义的最初副本数量为2，通过kubectl scale命令可以将Pod副本数量重新调整</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">kubectl scale rc redis-slave --replicas=3</span></span><br><span class="line">ReplicationController&quot;redis-slave&quot; scaled</span><br><span class="line"><span class="meta">#</span><span class="bash">kubectl get pods</span></span><br><span class="line">NAME READY STATUS RESTARTS AGE</span><br><span class="line">redis-slave-1sf23 1/1Running 0 1h</span><br><span class="line">redis-slave-54wfk 1/1Running 0 1h</span><br><span class="line">redis-slave-3da5y 1/1Running 0 1h　</span><br></pre></td></tr></table></figure><p>除了可以手工通过kubectl scale命令完成Pod的扩容和缩容操作以外，新版本新增加了Horizontal Podautoscaler(HPA)的控制器，用于实现基于CPU使用路进行启动Pod扩容缩容的功能。该控制器基于Mastger的kube-controller-manager服务启动参数 –horizontal-pod-autoscler-sync-period定义的时长（默认30秒），周期性监控目标Pod的Cpu使用率并在满足条件时对ReplicationController或Deployment中的Pod副本数量进行调整，以符合用户定义的平均Pod Cpu使用率，Pod Cpu使用率来源于heapster组件，所以需预先安装好heapster。</p></li><li><p>Pod的滚动升级</p><p>当集群中的某个服务需要升级时，我们需要停止目前与该服务相关的所有Pod，然后重新拉取镜像并启动。如果集群规模较大，因服务全部停止后升级的方式将导致长时间的服务不可用。由此，Kubernetes提供了rolling-update（滚动升级）功能来解决该问题。<br>滚动升级通过执行kubectl rolling-update命令一键完成，该命令创建一个新的RC，然后自动控制旧版本的Pod数量逐渐减少到0，同时新的RC中的Pod副本数量从0逐步增加到目标值，最终实现Pod的升级。需要注意的是，系统要求新的RC需要与旧的RC在相同的Namespace内，即不能把别人的资产转到到自家名下。</p><p>例：将redis-master从1.0版本升级到2.0</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">replicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">redis-master-v2</span></span><br><span class="line"><span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line">    <span class="attr">Version:</span> <span class="string">v2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">selector:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line">    <span class="attr">Version:</span> <span class="string">v2</span></span><br><span class="line"><span class="attr">template:</span></span><br><span class="line">    <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line">    <span class="attr">Version:</span> <span class="string">v2</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">    <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">master</span></span><br><span class="line">        <span class="attr">images:</span> <span class="string">kubeguide/redis-master:2.0</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">6379</span></span><br></pre></td></tr></table></figure><p>需要注意的点：</p><p>（1）RC的name不能与旧的RC名字相同</p><p>（2）在sele中应至少有一个label与旧的RC的label不同，以标识为新的RC。本例中新增了一个名为version的label与旧的RC区分</p><p>运行kubectl rolling-update来完成Pod的滚动升级：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">kubectl rolling-update redis-master -f redis-master-controller-v2.yaml</span> </span><br></pre></td></tr></table></figure><p>另一种方法就是不使用配置文件，直接用kubectl rolling-update加上–image参数指定新版镜像名来完成Pod的滚动升级</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">kubectl rolling-update redis-master --image=redis-master:2.0</span></span><br></pre></td></tr></table></figure><p>与使用配置文件的方式不同的是，执行的结果是旧的RC被删除，新的RC仍然使用就的RC的名字。<br>如果在更新过程总发现配置有误，则用户可以中断更新操作，并通过执行kubectl rolling-update-rollback完成Pod版本的回滚。</p></li></ol><div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p></div></section><section id="share"><div class="header"><span>分享文章</span></div><div class="body"><div class="link"><input class="copy-area" readonly id="copy-link" value="https://abnerwei.com/post/17db83fa"></div><div class="social-wrap dis-select"><a class="social share-item wechat" onclick="util.toggle(&quot;qrcode-wechat&quot)"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/social/b32ef3da1162a.svg"></a><a class="social share-item weibo" target="_blank" rel="external nofollow noopener noreferrer" href="https://service.weibo.com/share/share.php?url=https://abnerwei.com/post/17db83fa&title=Kubernetes基本介绍与集群部署 - Abnerwei&summary=Kubernetes集群Kubernetes是一个完备的分布式系统支撑平台，具有完备的集群管理能力，多扩多层次的安全防护和准入机制、多租户应用支撑能力、透明的服务注册和发现机制、內建智能负载均衡器、强大的故障发现和自我修复能力、服务滚..."><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/social/80c07e4dbb303.svg"></a><a class="social share-item email" href="mailto:?subject=Kubernetes基本介绍与集群部署 - Abnerwei&amp;body=https://abnerwei.com/post/17db83fa"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/social/a1b00e20f425d.svg"></a><a class="social share-item link" onclick="util.copy(&quot;copy-link&quot;, &quot;复制成功&quot;)"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/social/8411ed322ced6.svg"></a></div><div class="qrcode" id="qrcode-wechat" style="visibility:hidden;height:0"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://api.qrserver.com/v1/create-qr-code/?size=256x256&data=https://abnerwei.com/post/17db83fa"></div></div></section></div></article><div class="related-wrap reveal" id="read-next"><section class="header cap theme"><span>接下来阅读</span></section><section class="body fs14"><div class="line"></div><a id="prev" href="/post/ebaf3776">Golang面向对象特性<span class="note">较新</span></a><div class="line"></div><a id="more" href="/archives">检索全部文章</a></section></div><div class="related-wrap reveal" id="related-posts"></div><div class="related-wrap md reveal" id="comments"><div class="cmt-title cap theme">快来参与讨论吧</div><div class="cmt-body valine"><div id="valine_container" class="valine_thread"><svg class="loading" style="vertical-align:middle;fill:currentColor;overflow:hidden" viewbox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"/></svg></div></div></div><footer class="page-footer reveal fs12"><hr><div class="sitemap"><div class="sitemap-group"><span class="fs14">博文</span><a href="/">近期发布</a><a href="/categories/">分类</a><a href="/tags/">标签</a><a href="/archives/">归档</a></div><div class="sitemap-group"><span class="fs14">项目</span><a href="/wiki/categories/Go">Go</a></div><div class="sitemap-group"><span class="fs14">社交</span><a href="/friends/">友链</a><a href="/about/#comments">留言板</a></div><div class="sitemap-group"><span class="fs14">更多</span><a href="/about/">我是谁</a><a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/abnerwei">GitHub</a><a target="_blank" rel="external nofollow noopener noreferrer" href="https://gitee.com/abnerwei">Gitee</a></div></div><div class="text"><p>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p><p>本站由 <a href="https://abnerwei.com/">@Abnerwei</a> 创建，使用 <a target="_blank" rel="external nofollow noopener noreferrer" href="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.2.1">Stellar</a> 作为主题。</p></div></footer><div class="float-panel mobile-only blur" style="display:none"><button type="button" class="sidebar-toggle mobile" onclick="sidebar.toggle()"><svg class="icon" style="width:1em;height:1em;vertical-align:middle;fill:currentColor;overflow:hidden" viewbox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"/><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"/></svg></button></div></div></div><div class="scripts"><script type="text/javascript">stellar={loadCSS:(e,t,n,s)=>{var i,l=window.document,a=l.createElement("link");if(t)i=t;else{var r=(l.body||l.getElementsByTagName("head")[0]).childNodes;i=r[r.length-1]}var o=l.styleSheets;if(s)for(var d in s)s.hasOwnProperty(d)&&a.setAttribute(d,s[d]);a.rel="stylesheet",a.href=e,a.media="only x",function e(t){if(l.body)return t();setTimeout((function(){e(t)}))}((function(){i.parentNode.insertBefore(a,t?i:i.nextSibling)}));var u=function(e){for(var t=a.href,n=o.length;n--;)if(o[n].href===t)return e();setTimeout((function(){u(e)}))};function c(){a.addEventListener&&a.removeEventListener("load",c),a.media=n||"all"}return a.addEventListener&&a.addEventListener("load",c),a.onloadcssdefined=u,u(c),a},loadScript:(e,t)=>new Promise((n,s)=>{var i=document.createElement("script");if(i.src=e,t)for(let e of Object.keys(t))i[e]=t[e];else i.async=!0;i.onerror=s,i.onload=i.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(i.onload=i.onreadystatechange=null,n())},document.head.appendChild(i)}),jQuery:e=>{"undefined"==typeof jQuery?stellar.loadScript(stellar.plugins.jQuery).then(e):e()}},stellar.github="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.2.1",stellar.config={date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"}},stellar.plugins={jQuery:"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js",sitesjs:"/js/plugins/sites.js",friendsjs:"/js/plugins/friends.js"},stellar.plugins.lazyload=Object.assign({enable:!0,js:"https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.3.1/dist/lazyload.min.js",transition:"blur"}),stellar.plugins.swiper=Object.assign({enable:!0,css:"https://unpkg.com/swiper/swiper-bundle.min.css",js:"https://unpkg.com/swiper/swiper-bundle.min.js"}),stellar.plugins.preload=Object.assign({enable:!0,service:"flying_pages",instant_page:"https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js",flying_pages:"https://cdn.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"})</script><script src="/js/main.js" async></script><script>function getEmojiMaps(){function e(e,n,a){return e+"/"+e+"-"+n+"."+a}for(var n={},a=1;a<=54;a++)n["tieba-"+a]=e("tieba",a,"png");for(a=1;a<=101;a++)n["qq-"+a]=e("qq",a,"gif");for(a=1;a<=116;a++)n["aru-"+a]=e("aru",a,"gif");for(a=1;a<=125;a++)n["twemoji-"+a]=e("twemoji",a,"png");for(a=1;a<=4;a++)n["weibo-"+a]=e("weibo",a,"png");return n}function load_comment(){document.getElementById("valine_container")&&stellar.loadScript("https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@main/js/Valine.min.js",{defer:!0}).then((function(){var e=document.getElementById("valine_container").getAttribute("comment_id");e||(e=decodeURI(window.location.pathname)),(new Valine).init(Object.assign({js:"https://cdn.jsdelivr.net/gh/XuxuGood/simple-blog-cdn@main/js/Valine.min.js",appId:"O5783Ua1WhztyE6LgOgiCDVu-9Nh9j0Va",appKey:"qLUWtuQJaA3mgbLtov0yg6yX",placeholder:"ヾﾉ≧∀≦)o来啊，快活啊!",requiredFields:["nick","mail","link"],enableQQ:!0,recordIP:!0,avatar:"robohash",pageSize:10,lang:"zh-cn",highlight:!0,mathJax:!1,tagMeta:["博主","小伙伴","访客"],metaPlaceholder:{nick:"昵称/QQ号(必填)",mail:"邮箱（必填, 完全保密）",link:"网址(https://)"},master:["6783037F2DF30EAB99F9FC256157D875","8157614407170a34fe113a778da67f80"],friends:["6783037F2DF30EAB99F9FC256157D875","1fc9b27dc4fa362d9a5f194d66f7168f"]},{el:"#valine_container",path:e,placeholder:"ヾﾉ≧∀≦)o来啊，快活啊!",emojiCDN:"https://cdn.jsdelivr.net/gh/volantis-x/cdn-emoji/valine/",emojiMaps:getEmojiMaps()}))}))}window.addEventListener("DOMContentLoaded",e=>{console.log("DOM fully loaded and parsed"),load_comment()})</script></div></body></html>